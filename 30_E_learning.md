# 応用数学
### 行列計算  
- 固有値の計算
- 固有ベクトルの計算
【固有値、固有ベクトルの求め方】  
https://www.geisya.or.jp/~mwm48961/linear_algebra/eigenvalue2.htm  

### ベルヌーイ分布
2値の確率変数（例：表 or 裏） 
```
Φ∈[0,1]  

P(x=1) = Φ  
P(x=0) = 1-Φ  
```
tips:マルチヌーイ分布は多項分布のこと（例：サイコロの出目1~6）  

### ガウス分布(正規分布)
正規分布の基礎的な知識まとめ  
https://ai-trend.jp/basic-study/normal-distribution/normal-distribution/  

### ベイズの定理
例のやつ

### 特異値分解（SDV:Singular Value Deconposition）
良く分らん^^;  
SVD（特異値分解）解説  
https://qiita.com/sakami/items/d01fa353b4e1f48623a8  

詳しくはこれを買うと分かる（らしい）  
https://www.amazon.co.jp/ゼロから作るDeep-Learning-―自然言語処理編-斎藤-康毅/dp/4873118360  

### ノルム
ベクトル空間に対して「距離」を与えるための数学の道具のようなもの。  
【機械学習】LPノルムってなんだっけ？  
https://qiita.com/kenmatsu4/items/cecb466437da33df2870  

### カルバックライブラー情報量（KL-divergence）
良く分らん^^;  
https://www.youtube.com/watch?v=BHMTOffcvuE  
Kullback-Leibler Divergenceについてまとめる  
https://yul.hatenablog.com/entry/2019/01/07/152738  

### フロベニウスノルム
全成分の二乗和のルートのこと  
```
例
[[-2, 3, 2]
 [-1, 0, 4]
 [ 1,-1, 0]] → 6
```

### 情報量の計算
確率Pと置くと、log2(P)で計算できる。
エントロピー（entropy）入門 ～情報量とエントロピー～  
https://wwws.kobe-c.ac.jp/deguchi/sc180/info/ent0.html  

### 分布（用語だけ）
- 周辺確率
- 条件付き確率
- 同時確率分布
- 一様分布
- 混合分布
- 独立分布

### シャノンエントロピー I(x)
I(x) = -logP(x)

### シャノンエントロピー誤差
H(x) = -Σi P(xi)log(P(xi))

### 


















